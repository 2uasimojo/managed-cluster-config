apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: sre-cluster-monitoring-error-budget-burn
    role: alert-rules
  name: sre-cluster-monitoring-error-budget-burn
  namespace: openshift-monitoring
spec:
  groups:
  - name: sre-cluster-monitoring-error-budget-burn
    rules:
    # Substitues ClusterOperatorDown{name="monitoring"} as part of https://issues.redhat.com/browse/OSD-19769
    # Specifically ignore UserWorkload as part of this alert, we will look at that in another error
    - alert: ClusterMonitoringErrorBudgetBurnSRE
      expr: |
          1 - ( sum(sum_over_time(cluster_operator_up{name="monitoring",reason!~"UserWorkload.*"}[5m])) / sum(count_over_time(cluster_operator_up{name="monitoring",reason!~"UserWorkload.*"}[5m])) ) > (14.4 * (1 - 0.983))
          and
          1 - ( sum(sum_over_time(cluster_operator_up{name="monitoring",reason!~"UserWorkload.*"}[1h])) / sum(count_over_time(cluster_operator_up{name="monitoring",reason!~"UserWorkload.*"}[1h])) ) > (14.4 * (1 - 0.983))
      for: 2m
      labels:
        long_window: 1h
        severity: critical
        namespace: openshift-monitoring
        source: "https://issues.redhat.com/browse/OSD-19769"
        link: "https://github.com/openshift/ops-sop/blob/master/v4/troubleshoot/clusteroperators/monitoring.md"
        short_window: 5m
      annotations:
        message: "High error budget burn for the monitoring cluster operator (current value: {{ $value }})"
    - alert: ClusterMonitoringErrorBudgetBurnSRE
      expr: |
          1 - ( sum(sum_over_time(cluster_operator_up{name="monitoring",reason!~"UserWorkload.*"}[30m])) / sum(count_over_time(cluster_operator_up{name="monitoring",reason!~"UserWorkload.*"}[30m])) ) > (6 * (1 - 0.983))
          and
          1 - ( sum(sum_over_time(cluster_operator_up{name="monitoring",reason!~"UserWorkload.*"}[6h])) / sum(count_over_time(cluster_operator_up{name="monitoring",reason!~"UserWorkload.*"}[6h])) ) > (6 * (1 - 0.983))
      for: 15m
      labels:
        long_window: 6h
        severity: critical
        namespace: openshift-monitoring
        source: "https://issues.redhat.com/browse/OSD-19769"
        link: "https://github.com/openshift/ops-sop/blob/master/v4/troubleshoot/clusteroperators/monitoring.md"
        short_window: 30m
      annotations:
        message: "High error budget burn for the monitoring cluster operator (current value: {{ $value }})"

  - name: customer-user-workload-monitoring-error-budget-burn
    rules:
    # We want to specifically look at UserWorkloadMonitoring ErrorBudgetBurn here
    # The initial alert is a warning alert so that it shows up for the customer.
    # The longer-window alert is what fires a SL to the customer
    - alert: UserWorkloadMonitoringErrorBudgetBurn
      expr: |
          1 - ( sum(sum_over_time(cluster_operator_up{name="monitoring",reason=~".*UserWorkload.*"}[5m])) / sum(count_over_time(cluster_operator_up{name="monitoring",reason=~".*UserWorkload.*"}[5m])) ) > (14.4 * (1 - 0.983))
          and
          1 - ( sum(sum_over_time(cluster_operator_up{name="monitoring",reason=~".*UserWorkload.*"}[1h])) / sum(count_over_time(cluster_operator_up{name="monitoring",reason=~".*UserWorkload.*"}[1h])) ) > (14.4 * (1 - 0.983))
      for: 2m
      labels:
        long_window: 1h
        severity: warning
        namespace: openshift-monitoring
        link: "https://github.com/openshift/ops-sop/blob/master/v4/troubleshoot/clusteroperators/monitoring.md"
        short_window: 5m
      annotations:
        message: "High error budget burn for User Workload Monitoring (current value: {{ $value }})"
    - alert: UserWorkloadMonitoringErrorBudgetBurn
      expr: |
          1 - ( sum(sum_over_time(cluster_operator_up{name="monitoring",reason=~".*UserWorkload.*"}[30m])) / sum(count_over_time(cluster_operator_up{name="monitoring",reason=~".*UserWorkload.*"}[30m])) ) > (6 * (1 - 0.983))
          and
          1 - ( sum(sum_over_time(cluster_operator_up{name="monitoring",reason=~".*UserWorkload.*"}[6h])) / sum(count_over_time(cluster_operator_up{name="monitoring",reason=~".*UserWorkload.*"}[6h])) ) > (6 * (1 - 0.983))
      for: 15m
      labels:
        long_window: 6h
        severity: critical
        namespace: openshift-monitoring
        short_window: 30m
        send_managed_notification: "true"
        managed_notifcation_template: "UWMDeploymentErrorBudgetBurn"
      annotations:
        message: "High error budget burn for User Workload Monitoring (current value: {{ $value }})"
